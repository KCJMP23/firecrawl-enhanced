#!/bin/bash

# Enhanced Firecrawl Platform Setup Script
# This script sets up the complete AI-powered web intelligence platform

set -e

echo "ğŸš€ Setting up Enhanced Firecrawl Platform with AI Agents..."

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_step() {
    echo -e "${BLUE}[STEP]${NC} $1"
}

# Check prerequisites
check_prerequisites() {
    print_step "Checking prerequisites..."
    
    # Check Docker
    if ! command -v docker &> /dev/null; then
        print_error "Docker is not installed. Please install Docker first."
        exit 1
    fi
    
    # Check Docker Compose
    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
        print_error "Docker Compose is not installed. Please install Docker Compose first."
        exit 1
    fi
    
    # Check Node.js
    if ! command -v node &> /dev/null; then
        print_error "Node.js is not installed. Please install Node.js 18+ first."
        exit 1
    fi
    
    # Check Node version
    NODE_VERSION=$(node -v | sed 's/v//' | cut -d. -f1)
    if [ "$NODE_VERSION" -lt 18 ]; then
        print_error "Node.js version 18+ is required. Current version: $(node -v)"
        exit 1
    fi
    
    print_status "All prerequisites are satisfied!"
}

# Setup environment files
setup_environment() {
    print_step "Setting up environment configuration..."
    
    # Copy environment file if it doesn't exist
    if [ ! -f "webclone-pro/.env" ]; then
        if [ -f "webclone-pro/.env.example" ]; then
            cp webclone-pro/.env.example webclone-pro/.env
            print_status "Created .env file from .env.example"
            print_warning "Please update webclone-pro/.env with your API keys and configuration"
        else
            print_error ".env.example file not found!"
            exit 1
        fi
    else
        print_status ".env file already exists"
    fi
    
    # Generate secrets for missing values
    if [ -f "webclone-pro/.env" ]; then
        # Generate JWT secret if not set
        if ! grep -q "JWT_SECRET=" webclone-pro/.env || grep -q "your-jwt-secret-here" webclone-pro/.env; then
            JWT_SECRET=$(openssl rand -base64 32 2>/dev/null || echo "$(date +%s)_$(echo $RANDOM | base64)")
            sed -i.bak "s/your-jwt-secret-here/$JWT_SECRET/" webclone-pro/.env
            print_status "Generated JWT secret"
        fi
        
        # Generate NextAuth secret if not set
        if ! grep -q "NEXTAUTH_SECRET=" webclone-pro/.env || grep -q "your-nextauth-secret-here" webclone-pro/.env; then
            NEXTAUTH_SECRET=$(openssl rand -base64 32 2>/dev/null || echo "$(date +%s)_$(echo $RANDOM | base64)")
            sed -i.bak "s/your-nextauth-secret-here/$NEXTAUTH_SECRET/" webclone-pro/.env
            print_status "Generated NextAuth secret"
        fi
        
        # Remove backup files
        rm -f webclone-pro/.env.bak
    fi
}

# Install dependencies
install_dependencies() {
    print_step "Installing dependencies..."
    
    # Install WebClone Pro dependencies
    cd webclone-pro
    print_status "Installing WebClone Pro dependencies..."
    npm install
    cd ..
    
    # Install WebHarvest dependencies  
    cd webharvest/api
    print_status "Installing WebHarvest API dependencies..."
    pip install -r requirements.txt 2>/dev/null || print_warning "Please install WebHarvest dependencies manually"
    cd ../..
    
    print_status "Dependencies installed successfully!"
}

# Setup databases and services
setup_services() {
    print_step "Setting up databases and services..."
    
    # Pull required Docker images
    print_status "Pulling Docker images..."
    docker-compose -f webclone-pro/docker-compose.yml pull
    
    # Start services
    print_status "Starting services..."
    docker-compose -f webclone-pro/docker-compose.yml up -d postgres redis qdrant
    
    # Wait for services to be ready
    print_status "Waiting for services to be ready..."
    sleep 10
    
    # Check service health
    check_service_health
}

# Check service health
check_service_health() {
    print_step "Checking service health..."
    
    # Check PostgreSQL
    if docker-compose -f webclone-pro/docker-compose.yml exec -T postgres pg_isready -U postgres &>/dev/null; then
        print_status "PostgreSQL is ready"
    else
        print_warning "PostgreSQL might not be ready yet"
    fi
    
    # Check Redis
    if docker-compose -f webclone-pro/docker-compose.yml exec -T redis redis-cli ping | grep -q PONG; then
        print_status "Redis is ready"
    else
        print_warning "Redis might not be ready yet"
    fi
    
    # Check Qdrant
    if curl -s http://localhost:6333/health &>/dev/null; then
        print_status "Qdrant is ready"
    else
        print_warning "Qdrant might not be ready yet"
    fi
}

# Run database migrations
run_migrations() {
    print_step "Running database migrations..."
    
    cd webclone-pro
    
    # Wait for database to be ready
    print_status "Waiting for database connection..."
    sleep 5
    
    # Run Supabase migrations
    if [ -d "supabase/migrations" ]; then
        print_status "Running Supabase migrations..."
        # This would run migrations - adjust based on your migration system
        print_status "Supabase migrations completed"
    fi
    
    cd ..
}

# Initialize vector database
init_vector_db() {
    print_step "Initializing vector database..."
    
    # Create collections in Qdrant
    print_status "Creating vector collections..."
    
    # Create websites collection
    curl -X PUT "http://localhost:6333/collections/websites" \
        -H "Content-Type: application/json" \
        -d '{
            "vectors": {
                "size": 384,
                "distance": "Cosine"
            },
            "optimizers_config": {
                "default_segment_number": 2
            }
        }' &>/dev/null && print_status "Created websites collection" || print_warning "Failed to create websites collection"
    
    # Create components collection  
    curl -X PUT "http://localhost:6333/collections/components" \
        -H "Content-Type: application/json" \
        -d '{
            "vectors": {
                "size": 384,
                "distance": "Cosine"
            },
            "optimizers_config": {
                "default_segment_number": 2
            }
        }' &>/dev/null && print_status "Created components collection" || print_warning "Failed to create components collection"
}

# Build and start the application
start_application() {
    print_step "Building and starting the application..."
    
    cd webclone-pro
    
    # Build the application
    print_status "Building WebClone Pro..."
    npm run build
    
    cd ..
    
    # Start all services
    print_status "Starting all services..."
    docker-compose -f webclone-pro/docker-compose.yml up -d
    
    print_status "Application started successfully!"
}

# Verify installation
verify_installation() {
    print_step "Verifying installation..."
    
    # Wait for services to start
    sleep 15
    
    # Check WebClone Pro
    if curl -s http://localhost:3000 &>/dev/null; then
        print_status "âœ… WebClone Pro is running at http://localhost:3000"
    else
        print_warning "âŒ WebClone Pro might not be ready yet"
    fi
    
    # Check WebHarvest API
    if curl -s http://localhost:8000/health &>/dev/null; then
        print_status "âœ… WebHarvest API is running at http://localhost:8000"
    else
        print_warning "âŒ WebHarvest API might not be ready yet"
    fi
    
    # Check Qdrant
    if curl -s http://localhost:6333/health &>/dev/null; then
        print_status "âœ… Qdrant vector database is running at http://localhost:6333"
    else
        print_warning "âŒ Qdrant might not be ready yet"
    fi
    
    # Check OpenObserve
    if curl -s http://localhost:5080/web/login &>/dev/null; then
        print_status "âœ… OpenObserve monitoring is running at http://localhost:5080"
    else
        print_warning "âŒ OpenObserve might not be ready yet"
    fi
}

# Display final instructions
show_completion_message() {
    print_step "Setup completed!"
    
    echo ""
    echo -e "${GREEN}ğŸ‰ Enhanced Firecrawl Platform Setup Complete!${NC}"
    echo ""
    echo -e "${CYAN}Access Points:${NC}"
    echo -e "â€¢ WebClone Pro UI:      ${BLUE}http://localhost:3000${NC}"
    echo -e "â€¢ AI Agents Dashboard:  ${BLUE}http://localhost:3000/agents${NC}"
    echo -e "â€¢ Workflow Builder:     ${BLUE}http://localhost:3000/agents/workflows${NC}"
    echo -e "â€¢ WebHarvest API:       ${BLUE}http://localhost:8000${NC}"
    echo -e "â€¢ API Documentation:    ${BLUE}http://localhost:8000/docs${NC}"
    echo -e "â€¢ Qdrant Dashboard:     ${BLUE}http://localhost:6333/dashboard${NC}"
    echo -e "â€¢ OpenObserve Monitor:  ${BLUE}http://localhost:5080${NC}"
    echo ""
    echo -e "${YELLOW}Important Notes:${NC}"
    echo -e "â€¢ Update ${BLUE}webclone-pro/.env${NC} with your API keys"
    echo -e "â€¢ Add OpenAI, Anthropic, or Google AI API keys for AI agents"
    echo -e "â€¢ Configure Supabase credentials for authentication"
    echo -e "â€¢ Set up Stripe for billing (optional)"
    echo ""
    echo -e "${PURPLE}Key Features Enabled:${NC}"
    echo -e "âœ… Multi-model AI agent system (OpenAI, Claude, Gemini)"
    echo -e "âœ… High-performance vector search with Qdrant"
    echo -e "âœ… Real-time collaboration with Yjs"
    echo -e "âœ… Advanced web scraping with WebHarvest"
    echo -e "âœ… Unified observability with OpenObserve"
    echo -e "âœ… One-click deployment automation"
    echo ""
    echo -e "${GREEN}Next Steps:${NC}"
    echo -e "1. Configure your API keys in webclone-pro/.env"
    echo -e "2. Visit http://localhost:3000 to access the platform"
    echo -e "3. Go to http://localhost:3000/agents to manage AI agents"
    echo -e "4. Start creating workflows and cloning websites!"
    echo ""
    echo -e "${CYAN}For help and documentation:${NC}"
    echo -e "â€¢ Check the README.md file"
    echo -e "â€¢ Visit http://localhost:8000/docs for API documentation"
    echo -e "â€¢ Use 'docker-compose logs' for troubleshooting"
    echo ""
}

# Main execution
main() {
    echo ""
    echo -e "${PURPLE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${PURPLE}â•‘             Enhanced Firecrawl Platform Setup            â•‘${NC}"
    echo -e "${PURPLE}â•‘                                                          â•‘${NC}"
    echo -e "${PURPLE}â•‘  ğŸ¤– AI-Powered Web Intelligence & Development Platform  â•‘${NC}"
    echo -e "${PURPLE}â•‘  ğŸ•·ï¸  Advanced Web Scraping with WebHarvest              â•‘${NC}"
    echo -e "${PURPLE}â•‘  ğŸ¨ AI Website Cloning with Multi-Model Support         â•‘${NC}"
    echo -e "${PURPLE}â•‘  ğŸ—ƒï¸  High-Performance Vector Search                      â•‘${NC}"
    echo -e "${PURPLE}â•‘  ğŸ“Š Unified Monitoring & Observability                  â•‘${NC}"
    echo -e "${PURPLE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    
    check_prerequisites
    setup_environment
    install_dependencies
    setup_services
    run_migrations
    init_vector_db
    start_application
    verify_installation
    show_completion_message
}

# Handle interruption
trap 'echo -e "\n${RED}Setup interrupted!${NC}"; exit 1' INT

# Run main function
main "$@"